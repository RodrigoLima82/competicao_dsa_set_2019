{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Competição DSA de Machine Learning\n# Edição Setembro/2019\n\n##### Referencias\n- https://www.kaggle.com/c/career-con-2019\n- https://www.kaggle.com/artgor/where-do-the-robots-drive\n- https://www.kaggle.com/gpreda/robots-need-help\n- https://www.kaggle.com/friedchips/the-missing-link\n- https://www.kaggle.com/c/career-con-2019/discussion/87239"},{"metadata":{},"cell_type":"markdown","source":"# Importando as bibliotecas que serão utilizadas neste projeto"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pacotes basicos\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport itertools\nimport imblearn\nimport math\n\n# Metricas e Graficos\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\nfrom seaborn import countplot, lineplot, barplot\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom scipy.stats import kurtosis, skew\n\n# Modelos\nfrom sklearn.model_selection import KFold, cross_val_score, StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n\n# Tratamento de warning e exibição no Jupyter\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\npd.options.display.max_seq_items = 8000\npd.options.display.max_rows = 8000\npd.set_option('display.max_columns', None)\n\n# Matplot \nimport matplotlib.pyplot as plt\nimport matplotlib.style as style \n%matplotlib inline\nstyle.use('ggplot')\n\n# Outras libs\nimport pickle\nimport os\nfrom time import time\nimport gc\ngc.enable()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Carregando os dados"},{"metadata":{"trusted":true},"cell_type":"code","source":"treino = pd.read_csv('../input/competicao-dsa-machine-learning-sep-2019/X_treino.csv')\nteste = pd.read_csv('../input/competicao-dsa-machine-learning-sep-2019/X_teste.csv')\ntarget = pd.read_csv('../input/competicao-dsa-machine-learning-sep-2019/y_treino.csv')\nsub = pd.read_csv('../input/competicao-dsa-machine-learning-sep-2019/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Análise Exploratória (EAD)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Primeiros registros do dataset de treino\ntreino.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Primeiros registros do dataset de teste\nteste.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Primeiros registros do dataset target\ntarget.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analise estatística do dataset de treino\ntreino.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analise estatística do dataset de teste\nteste.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analise estatística do dataset target\ntarget.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cada serie tem 128 medidas\nlen(treino.measurement_number.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificar se existem dados nulos no dataset de treino\ntreino.isnull().values.any() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificar se existem dados nulos no dataset de teste\nteste.isnull().values.any() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Existem 6 series a mais no dataset de teste\n(teste.shape[0] - treino.shape[0]) / 128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Existe 73 grupos unicos no dataset target \ntarget['group_id'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizando todos os tipos de superfície do dataset target, ordenado pela quantidade de registros\nsns.countplot(y = 'surface',\n              data = target,\n              order = target['surface'].value_counts().index)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualização dos Grupos"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizando a distribuição das features: group_id e surface\n# Créditos: https://www.kaggle.com/gpreda/robots-need-help\nfig, ax = plt.subplots(1,1,figsize=(26,8))\ngrp = pd.DataFrame(target.groupby(['group_id', 'surface'])['series_id'].count().reset_index())\npiv = grp.pivot(index='surface', columns='group_id', values='series_id')\ngrafico = sns.heatmap(piv, linewidths=.1, linecolor='black', annot=True, cmap=\"YlGnBu\")\ngrafico.set_title('Surface x Grupo_id', size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grafico de contador de numero de registros por group_id, ordenado\nplt.figure(figsize=(23,5)) \ncountplot(x=\"group_id\", data=target, order=target['group_id'].value_counts().index)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualização das Series"},{"metadata":{"trusted":true},"cell_type":"code","source":"series_dict = {}\nfor series in (treino['series_id'].unique()):\n    series_dict[series] = treino[treino['series_id'] == series]  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_series(series_id):\n    plt.figure(figsize=(28, 16))\n    print(target[target['series_id'] == series_id]['surface'].values[0].title())\n    for i, col in enumerate(series_dict[series_id].columns[3:]):\n        if col.startswith(\"o\"):\n            color = 'red'\n        elif col.startswith(\"a\"):\n            color = 'green'\n        else:\n            color = 'blue'\n        if i >= 7:\n            i+=1\n        plt.subplot(3, 4, i + 1)\n        plt.plot(series_dict[series_id][col], color=color, linewidth=3)\n        plt.title(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizando a serie de código 0\nid_series = 0\nplot_series(id_series)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlação"},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(treino.iloc[:,3:].corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gráficos de Distribuição"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_distribution(df1, df2, label1, label2, features,a=2,b=5):\n    i = 0\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(a,b,figsize=(17,9))\n\n    for feature in features:\n        i += 1\n        plt.subplot(a,b,i)\n        sns.kdeplot(df1[feature], bw=0.5,label=label1)\n        sns.kdeplot(df2[feature], bw=0.5,label=label2)\n        plt.xlabel(feature, fontsize=9)\n        locs, labels = plt.xticks()\n        plt.tick_params(axis='x', which='major', labelsize=8)\n        plt.tick_params(axis='y', which='major', labelsize=8)\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gráfico de distribuição por dataset (treino x teste)\nfeatures = treino.columns.values[3:]\nplot_distribution(treino, teste, 'Treino', 'Teste', features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_classes_distribution(classes, tt, features,a=5,b=2):\n    i = 0\n    plt.figure()\n    fig, ax = plt.subplots(a,b,figsize=(16,24))\n\n    for feature in features:\n        i += 1\n        plt.subplot(a,b,i)\n        for cl in classes:\n            ttc = tt[tt['surface']==cl]\n            sns.kdeplot(ttc[feature], bw=0.5,label=cl)\n        plt.xlabel(feature, fontsize=9)\n        locs, labels = plt.xticks()\n        plt.tick_params(axis='x', which='major', labelsize=8)\n        plt.tick_params(axis='y', which='major', labelsize=8)\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gráfico de distribuição por classe\nclasses = (target['surface'].value_counts()).index\naux = treino.merge(target, on='series_id', how='inner')\nplot_classes_distribution(classes, aux, features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Enginnering"},{"metadata":{},"cell_type":"markdown","source":"### Criando funções auxiliares para definição de novas features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Funcao para converter Quaternions para Angulos de Euler\ndef quaternion_to_euler(x, y, z, w):\n\n    t0 = +2.0 * (w * x + y * z)\n    t1 = +1.0 - 2.0 * (x * x + y * y)\n    X = math.atan2(t0, t1)\n\n    t2 = +2.0 * (w * y - z * x)\n    t2 = +1.0 if t2 > +1.0 else t2\n    t2 = -1.0 if t2 < -1.0 else t2\n    Y = math.asin(t2)\n\n    t3 = +2.0 * (w * z + x * y)\n    t4 = +1.0 - 2.0 * (y * y + z * z)\n    Z = math.atan2(t3, t4)\n\n    return X, Y, Z\n\n# Funções para criação de features estatísticas\ndef _kurtosis(x):\n    return kurtosis(x)\n\ndef skewness(x):\n    return skew(x)\n\ndef SSC(x):\n    x = np.array(x)\n    x = np.append(x[-1], x)\n    x = np.append(x,x[1])\n    xn = x[1:len(x)-1]\n    xn_i2 = x[2:len(x)]    \n    xn_i1 = x[0:len(x)-2]  \n    ans = np.heaviside((xn-xn_i1)*(xn-xn_i2),0)\n    return sum(ans[1:]) \n\ndef wave_length(x):\n    x = np.array(x)\n    x = np.append(x[-1], x)\n    x = np.append(x,x[1])\n    xn = x[1:len(x)-1]\n    xn_i2 = x[2:len(x)]    \n    return sum(abs(xn_i2-xn))\n    \ndef norm_entropy(x):\n    tresh = 3\n    return sum(np.power(abs(x),tresh))\n\ndef SRAV(x):    \n    SRA = sum(np.sqrt(abs(x)))\n    return np.power(SRA/len(x),2)\n\ndef mean_abs(x):\n    return sum(abs(x))/len(x)\n\ndef zero_crossing(x):\n    x = np.array(x)\n    x = np.append(x[-1], x)\n    x = np.append(x,x[1])\n    xn = x[1:len(x)-1]\n    xn_i2 = x[2:len(x)]    # xn+1\n    return sum(np.heaviside(-xn*xn_i2,0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Função para criação de novas features\ndef fn_features_01(df):\n    df['totl_anglr_vel'] = (df['angular_velocity_X']**2 + df['angular_velocity_Y']**2 + df['angular_velocity_Z']**2)** 0.5\n    df['totl_linr_acc'] = (df['linear_acceleration_X']**2 + df['linear_acceleration_Y']**2 + df['linear_acceleration_Z']**2)**0.5\n    df['totl_xyz'] = (df['orientation_X']**2 + df['orientation_Y']**2 + df['orientation_Z']**2)**0.5\n    df['acc_vs_vel'] = df['totl_linr_acc'] / df['totl_anglr_vel']\n    df['norm_quat'] = (df['orientation_X']**2 + df['orientation_Y']**2 + df['orientation_Z']**2 + df['orientation_W']**2)\n    df['mod_quat'] = (df['norm_quat'])**0.5\n    df['norm_X'] = df['orientation_X'] / df['mod_quat']\n    df['norm_Y'] = df['orientation_Y'] / df['mod_quat']\n    df['norm_Z'] = df['orientation_Z'] / df['mod_quat']\n    df['norm_W'] = df['orientation_W'] / df['mod_quat']\n    \n    x, y, z, w = df['norm_X'].tolist(), df['norm_Y'].tolist(), df['norm_Z'].tolist(), df['norm_W'].tolist()\n    nx, ny, nz = [], [], []\n    for i in range(len(x)):\n        xx, yy, zz = quaternion_to_euler(x[i], y[i], z[i], w[i])\n        nx.append(xx)\n        ny.append(yy)\n        nz.append(zz)\n    \n    df['euler_x'] = nx\n    df['euler_y'] = ny\n    df['euler_z'] = nz\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Função para criação de novas features, agrupando por series_id\ndef fn_features_02(data):\n    df = pd.DataFrame()\n    \n    def mean_change_of_abs_change(x):\n        return np.mean(np.diff(np.abs(np.diff(x))))\n    \n    for col in data.columns:\n        if col in ['row_id','series_id','measurement_number', 'orientation_X', 'orientation_Y', 'orientation_Z', 'orientation_W']:\n            continue\n        df[col + '_mean'] = data.groupby(['series_id'])[col].mean()\n        df[col + '_median'] = data.groupby(['series_id'])[col].median()\n        df[col + '_max'] = data.groupby(['series_id'])[col].max()\n        df[col + '_min'] = data.groupby(['series_id'])[col].min()\n        df[col + '_std'] = data.groupby(['series_id'])[col].std()\n        df[col + '_range'] = df[col + '_max'] - df[col + '_min']\n        df[col + '_maxtoMin'] = df[col + '_max'] / df[col + '_min']\n        df[col + '_mean_abs_chg'] = data.groupby(['series_id'])[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        df[col + '_mean_change_of_abs_change'] = data.groupby('series_id')[col].apply(mean_change_of_abs_change)\n        df[col + '_abs_max'] = data.groupby(['series_id'])[col].apply(lambda x: np.max(np.abs(x)))\n        df[col + '_abs_min'] = data.groupby(['series_id'])[col].apply(lambda x: np.min(np.abs(x)))\n        df[col + '_abs_avg'] = (df[col + '_abs_min'] + df[col + '_abs_max'])/2\n        \n        # Advanced Features\n        df[col + '_skew'] = data.groupby(['series_id'])[col].skew()\n        df[col + '_mad'] = data.groupby(['series_id'])[col].mad()\n        df[col + '_q25'] = data.groupby(['series_id'])[col].quantile(0.25)\n        df[col + '_q75'] = data.groupby(['series_id'])[col].quantile(0.75)\n        df[col + '_q95'] = data.groupby(['series_id'])[col].quantile(0.95)\n        df[col + '_iqr'] = df[col + '_q75'] - df[col + '_q25']\n        df[col + '_SSC'] = data.groupby(['series_id'])[col].apply(SSC) \n        df[col + '_skewness'] = data.groupby(['series_id'])[col].apply(skewness)\n        df[col + '_wave_lenght'] = data.groupby(['series_id'])[col].apply(wave_length)\n        df[col + '_norm_entropy'] = data.groupby(['series_id'])[col].apply(norm_entropy)\n        df[col + '_SRAV'] = data.groupby(['series_id'])[col].apply(SRAV)\n        df[col + '_kurtosis'] = data.groupby(['series_id'])[col].apply(_kurtosis) \n        df[col + '_zero_crossing'] = data.groupby(['series_id'])[col].apply(zero_crossing) \n\n    return df\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Aplicando novas features nos datasets de treino e teste\ntreino = fn_features_01(treino)\nteste = fn_features_01(teste)\ntreino.shape, teste.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Aplicando novas features nos datasets de treino e teste\n# Esta celula demora um pouco para concluir (cerca de 10min)\ntreino = fn_features_02(treino)\nteste = fn_features_02(teste)\ntreino.shape, teste.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizando os primeiros registros do dataset de treino com as novas features\ntreino.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preenchendo os valores NA e inf com zero\n# Acontece após a criação das novas variáveis estatísticas\ntreino.fillna(0,inplace=True)\ntreino.replace(-np.inf,0,inplace=True)\ntreino.replace(np.inf,0,inplace=True)\n\nteste.fillna(0,inplace=True)\nteste.replace(-np.inf,0,inplace=True)\nteste.replace(np.inf,0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transformando a feature 'surface' de string para numérico\nle = preprocessing.LabelEncoder()\ntarget['surface'] = le.fit_transform(target['surface'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Criação e Validação dos Modelos de Machine Learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Utilizando o método StratifiedKFold para realizar os grupos de treinamento\nfolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=2019)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"previsao = np.zeros((teste.shape[0],9))\nreal = np.zeros((treino.shape[0]))\nscore = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Execução da criação e treinamento do modelo\n# Utilização do algoritmo RANDOM FOREST CLASSIFIER\n\nfor times, (trn_idx, val_idx) in enumerate(folds.split(treino.values, target['surface'].values)):\n    rf = RandomForestClassifier(n_estimators=500, n_jobs = -1)\n    rf.fit(treino.iloc[trn_idx], target['surface'][trn_idx])\n    real[val_idx] = rf.predict(treino.iloc[val_idx])\n    previsao += rf.predict_proba(teste) / folds.n_splits\n    score += rf.score(treino.iloc[val_idx], target['surface'][val_idx])\n    print(\"Fold: {} score: {}\".format(times, rf.score(treino.iloc[val_idx], target['surface'][val_idx])))\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Acuracia Media: ', score / folds.n_splits)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(real, target['surface'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submissão Kaggle"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['surface'] = le.inverse_transform(previsao.argmax(axis=1))\n#sub.to_csv('submission_rf.csv', index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gerando submissão usando link entre dataset de treino e teste\n##### Créditos: https://www.kaggle.com/friedchips/the-missing-link"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Carregando novamente os datasets\ntt_treino = pd.read_csv('../input/competicao-dsa-machine-learning-sep-2019/X_treino.csv')\ntt_teste = pd.read_csv('../input/competicao-dsa-machine-learning-sep-2019/X_teste.csv')\ntt_y_treino = pd.read_csv('../input/competicao-dsa-machine-learning-sep-2019/y_treino.csv')\nss = pd.read_csv('../input/competicao-dsa-machine-learning-sep-2019/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatenando os datasets de treino e teste\nfull = pd.concat([tt_treino, tt_teste])\nfull = full.iloc[:,3:].values.reshape(-1,128,10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Funções para calcular a distancia entre as amostras de dados\n# O objetivo é identificar links entre os datasets de treino e teste\n# Caso exista relações, estas serão utilizadas para avaliação no Kaggle\ndef sq_dist(a,b):\n    return np.sum((a-b)**2, axis=1)\n\ndef find_run_edges(data, edge):\n    if edge == 'left':\n        border1 = 0\n        border2 = -1\n    elif edge == 'right':\n        border1 = -1\n        border2 = 0\n    else:\n        return False\n    \n    edge_list = []\n    linked_list = []\n    \n    for i in range(len(data)):\n        dist_list = sq_dist(data[i, border1, :4], data[:, border2, :4])\n        min_dist = np.min(dist_list)\n        closest_i   = np.argmin(dist_list)\n        if closest_i == i:\n            closest_i = np.argsort(dist_list)[1]\n        dist_list = sq_dist(data[closest_i, border2, :4], data[:, border1, :4])\n        rev_dist = np.min(dist_list)\n        closest_rev = np.argmin(dist_list)\n        if closest_rev == closest_i:\n            closest_rev = np.argsort(dist_list)[1]\n        if (i != closest_rev):\n            edge_list.append(i)\n        else:\n            linked_list.append([i, closest_i, min_dist])\n            \n    return edge_list, linked_list\n\ndef find_runs(data, left_edges, right_edges):\n    data_runs = []\n\n    for start_point in left_edges:\n        i = start_point\n        run_list = [i]\n        while i not in right_edges:\n            tmp = np.argmin(sq_dist(data[i, -1, :4], data[:, 0, :4]))\n            if tmp == i: # self-linked sample\n                tmp = np.argsort(sq_dist(data[i, -1, :4], data[:, 0, :4]))[1]\n            i = tmp\n            run_list.append(i)\n        data_runs.append(np.array(run_list))\n    \n    return data_runs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Procurando por link entre os dados\ntrain_left_edges, train_left_linked  = find_run_edges(full, edge='left')\ntrain_right_edges, train_right_linked = find_run_edges(full, edge='right')\ntrain_runs = find_runs(full, train_left_edges, train_right_edges)\nprint('Found', len(train_left_edges), 'left edges and', len(train_right_edges), 'right edges.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss['surface'] = ''\ndf_surface = ''\n\nfor i in range(151):\n    x = train_runs[i]\n    x = np.sort(x)\n    if x[0]<3810:\n        df_surface = tt_y_treino['surface'][x[0]]\n        for j in range(len(train_runs[i])):\n            if train_runs[i][j]-3810>-1:\n                ss['surface'][train_runs[i][j]-3810] = df_surface","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gerando a melhor submissão para o Kaggle"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_runs = ss.copy()\n\nsub_final = {}\nfor i in range(0, sub.shape[0]):\n    sub_final.update({sub.iloc[i]['series_id'] : sub.iloc[i]['surface'] })\n    \ny_train_runs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resultado = []\nfor i in range(0, y_train_runs.shape[0]):\n    if (y_train_runs.surface[i] == ''):\n        resultado.append(sub_final[i])\n    else:\n        resultado.append(y_train_runs.surface[i])\n        \ny_train_runs['surface'] = resultado\ny_train_runs.to_csv('best_submission_rf.csv', index=False)\ny_train_runs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_runs.surface.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_runs.surface.value_counts() / y_train_runs.shape[0]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}